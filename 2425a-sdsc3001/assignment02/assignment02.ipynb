{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDSC3001 - Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Assignment_2](./SDSC3001%20-%20Assignment%202.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(file_path):\n",
    "    edges = []\n",
    "    with open(file_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            if line.startswith(\"#\"):\n",
    "                continue  # Skip comment lines\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 2:\n",
    "                from_node, to_node = map(int, parts)\n",
    "                edges.append((from_node, to_node))\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"com-dblp.txt\"\n",
    "graph_edges = load_graph(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def power_iteration_pagerank(graph_edges, alpha=0.15, tolerance=1e-9):\n",
    "    # Get unique nodes in the graph to determine the number of nodes (n)\n",
    "    nodes = set()\n",
    "    for edge in graph_edges:\n",
    "        nodes.update(edge)\n",
    "    nodes = list(nodes)\n",
    "    n = len(nodes)\n",
    "\n",
    "    # Initialize the PageRank vector\n",
    "    pi = np.full(n, 1 / n)\n",
    "    prev_pi = np.zeros(n)\n",
    "\n",
    "    # Create a mapping from node ID to index and vice versa\n",
    "    node_to_index = {node: index for index, node in enumerate(nodes)}\n",
    "    index_to_node = {index: node for index, node in enumerate(nodes)}\n",
    "\n",
    "    # Create an adjacency list from the graph edges\n",
    "    adjacency_list = {node: [] for node in nodes}\n",
    "    for from_node, to_node in graph_edges:\n",
    "        adjacency_list[from_node].append(to_node)\n",
    "\n",
    "    # Perform power iterations\n",
    "    iteration_count = 0\n",
    "    while np.max(np.abs(pi - prev_pi)) > tolerance:\n",
    "        prev_pi = pi.copy()\n",
    "        pi = np.zeros(n)\n",
    "\n",
    "        for node, index in node_to_index.items():\n",
    "            outbound_neighbors = adjacency_list[node]\n",
    "            if len(outbound_neighbors) == 0:\n",
    "                continue\n",
    "\n",
    "            for neighbor in outbound_neighbors:\n",
    "                neighbor_index = node_to_index[neighbor]\n",
    "                pi[neighbor_index] += prev_pi[index] / len(outbound_neighbors)\n",
    "\n",
    "        pi = (1 - alpha) * pi + alpha / n\n",
    "        iteration_count += 1\n",
    "\n",
    "    print(f\"Converged in {iteration_count} iterations.\")\n",
    "\n",
    "    # Convert the PageRank vector back to a dictionary with node IDs as keys\n",
    "    pagerank_dict = {index_to_node[i]: rank for i, rank in enumerate(pi)}\n",
    "\n",
    "    return pagerank_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged in 17 iterations.\n"
     ]
    }
   ],
   "source": [
    "power_iter_pagerank = power_iteration_pagerank(graph_edges, alpha=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random walk from Assignment 1\n",
    "\n",
    "```python\n",
    "import random\n",
    "\n",
    "\n",
    "def simulate_random_walk(graph_edges, num_steps, seed=42):\n",
    "    random.seed(seed)\n",
    "\n",
    "    neighbors = {}\n",
    "    for from_node, to_node in graph_edges:\n",
    "        if from_node not in neighbors:\n",
    "            neighbors[from_node] = []\n",
    "        if to_node not in neighbors:\n",
    "            neighbors[to_node] = []\n",
    "        neighbors[from_node].append(to_node)\n",
    "        neighbors[to_node].append(from_node)\n",
    "\n",
    "    current_node = random.choice(list(neighbors.keys()))\n",
    "    visit_counts = {node: 0 for node in neighbors.keys()}\n",
    "\n",
    "    for _ in range(num_steps):\n",
    "        visit_counts[current_node] += 1\n",
    "        current_node = random.choice(neighbors[current_node])\n",
    "\n",
    "    return visit_counts\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def monte_carlo_pagerank(graph_edges, alpha, num_walks):\n",
    "    # Get unique nodes in the graph to determine the number of nodes (n)\n",
    "    nodes = set()\n",
    "    for edge in graph_edges:\n",
    "        nodes.update(edge)\n",
    "    nodes = list(nodes)\n",
    "    \n",
    "    # Create a mapping from node ID to index and vice versa\n",
    "    node_to_index = {node: index for index, node in enumerate(nodes)}\n",
    "    \n",
    "    # Create an adjacency list from the graph edges\n",
    "    adjacency_list = {node: [] for node in nodes}\n",
    "    for from_node, to_node in graph_edges:\n",
    "        adjacency_list[from_node].append(to_node)\n",
    "\n",
    "    f_v = defaultdict(int)\n",
    "    \n",
    "    for _ in range(num_walks):\n",
    "        start_node = random.choice(nodes)\n",
    "        current_node = start_node\n",
    "        \n",
    "        while True:\n",
    "            if random.random() < alpha:\n",
    "                # Stop the random walk with probability alpha\n",
    "                break\n",
    "            \n",
    "            neighbors = adjacency_list[current_node]\n",
    "            if not neighbors:\n",
    "                break  # stop if there are no neighbors to move to\n",
    "            \n",
    "            # Move to a random neighbor with probability 1-alpha\n",
    "            current_node = random.choice(neighbors)\n",
    "        \n",
    "        f_v[current_node] += 1\n",
    "    \n",
    "    # Estimate PageRank values using f_v counts\n",
    "    est_pagerank = np.zeros(len(nodes))\n",
    "    for node, count in f_v.items():\n",
    "        index = node_to_index[node]\n",
    "        est_pagerank[index] = count / num_walks\n",
    "    \n",
    "    return est_pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_difference(power_iteration_pi, monte_carlo_est):\n",
    "    difference = np.sum(np.abs(power_iteration_pi - monte_carlo_est))\n",
    "    return difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M = 634160, Difference = 0.9007271828211119\n",
      "M = 1268320, Difference = 0.8402100561294962\n",
      "M = 1902480, Difference = 0.8173469649443026\n",
      "M = 2536640, Difference = 0.8060844092001701\n",
      "M = 3170800, Difference = 0.7968972425552688\n"
     ]
    }
   ],
   "source": [
    "nodes = list(power_iter_pagerank.keys())\n",
    "power_iter_pi = np.array([power_iter_pagerank[node] for node in nodes])\n",
    "\n",
    "\n",
    "n = len(nodes)\n",
    "results = {}\n",
    "\n",
    "for M in [2 * n, 4 * n, 6 * n, 8 * n, 10 * n]:\n",
    "    monte_carlo_est = monte_carlo_pagerank(graph_edges, alpha=0.15, num_walks=M)\n",
    "    difference = compute_difference(power_iter_pi, monte_carlo_est)\n",
    "    results[M] = difference\n",
    "    print(f'M = {M}, Difference = {difference}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_pagerank_new(graph_edges, alpha, num_walks):\n",
    "    # Get unique nodes in the graph to determine the number of nodes (n)\n",
    "    nodes = set()\n",
    "    for edge in graph_edges:\n",
    "        nodes.update(edge)\n",
    "    nodes = list(nodes)\n",
    "    \n",
    "    # Number of nodes in the graph\n",
    "    n = len(nodes)\n",
    "    \n",
    "    # Create a mapping from node ID to index and vice versa\n",
    "    node_to_index = {node: index for index, node in enumerate(nodes)}\n",
    "\n",
    "    # Create an adjacency list from the graph edges\n",
    "    adjacency_list = {node: [] for node in nodes}\n",
    "    for from_node, to_node in graph_edges:\n",
    "        adjacency_list[from_node].append(to_node)\n",
    "\n",
    "    # Initialize count of each node appearances\n",
    "    s_v = defaultdict(int)\n",
    "    \n",
    "    # Perform Monte Carlo walks\n",
    "    for _ in range(num_walks):\n",
    "        start_node = random.choice(nodes)\n",
    "        current_node = start_node\n",
    "        \n",
    "        while True:\n",
    "            # Increment count for the current node\n",
    "            s_v[current_node] += 1\n",
    "\n",
    "            if random.random() < alpha:\n",
    "                # Stop the random walk with probability alpha\n",
    "                break\n",
    "            \n",
    "            neighbors = adjacency_list.get(current_node, [])\n",
    "            if not neighbors:\n",
    "                break  # Stop if there are no neighbors to move to\n",
    "            \n",
    "            # Move to a random neighbor with probability 1-alpha\n",
    "            current_node = random.choice(neighbors)\n",
    "    \n",
    "    # Calculate the refined PageRank estimates\n",
    "    est_pagerank = np.zeros(n)\n",
    "    for node in nodes:\n",
    "        index = node_to_index[node]\n",
    "        est_pagerank[index] = (alpha * s_v[node]) / num_walks\n",
    "    \n",
    "    return est_pagerank, nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_difference_new(edges, alpha, n, m_values):\n",
    "    differences = {}\n",
    "    for m_multiplier in m_values:\n",
    "        num_walks = m_multiplier * n\n",
    "        est_pagerank, nodes = monte_carlo_pagerank_new(edges, alpha, num_walks)\n",
    "\n",
    "        diff_sum = 0\n",
    "        for i in range(len(est_pagerank)):\n",
    "            true_pagerank = 1 / len(nodes)\n",
    "            diff_sum += abs(est_pagerank[i] - true_pagerank)\n",
    "        \n",
    "        differences[m_multiplier] = diff_sum\n",
    "        print(f\"M = {num_walks}, Sum of differences: {diff_sum:.4f}\")\n",
    "    \n",
    "    return differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M = 634160, Sum of differences: 0.7303\n",
      "M = 1268320, Sum of differences: 0.7292\n",
      "M = 1902480, Sum of differences: 0.7284\n",
      "M = 2536640, Sum of differences: 0.7285\n",
      "M = 3170800, Sum of differences: 0.7285\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.15\n",
    "nodes_count = len(set(edge[0] for edge in graph_edges).union(set(edge[1] for edge in graph_edges)))\n",
    "\n",
    "m_values = [2, 4, 6, 8, 10]\n",
    "\n",
    "difference_sums = compute_difference_new(graph_edges, alpha, nodes_count, m_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, $\\frac{\\alpha s_v}{M}$ is an unbiased estimator for $\\pi_v$ because the expected value of our PageRank estimate equals the true PageRank $\\pi_v$. The randomness of the starting node and the walk leads to a fair distribution of visits."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
