{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDSC3001 - Course Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard similarity coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Similarity: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "def jaccard_similarity(set1, set2):\n",
    "    intersection = set1.intersection(set2)\n",
    "    union = set1.union(set2)\n",
    "    return len(intersection) / len(union)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "set1 = {\"a\", \"b\", \"c\", \"d\"}\n",
    "set2 = {\"c\", \"d\", \"e\", \"f\"}\n",
    "\n",
    "similarity = jaccard_similarity(set1, set2)\n",
    "print(f\"Jaccard Similarity: {similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sketching techniques for the Jaccard similarity coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import mmh3\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import random\n",
    "\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "\n",
    "def generate_synthetic_stream(cardinality, jaccard_true):\n",
    "    total_num = cardinality * 2\n",
    "    sim = (2 * jaccard_true) / (1 + jaccard_true)\n",
    "    the_same_index = total_num / 2 * sim\n",
    "    setA_uni_index = total_num / 2 * 1\n",
    "    setB_uni_index = total_num / 2 * (2 - sim)\n",
    "\n",
    "    stream = []\n",
    "    for num in range(total_num):\n",
    "        if num <= the_same_index:\n",
    "            stream.append([\"setA\", num])\n",
    "            stream.append([\"setB\", num])\n",
    "        elif num <= setA_uni_index:\n",
    "            stream.append([\"setA\", num])\n",
    "        elif num <= setB_uni_index:\n",
    "            stream.append([\"setB\", num])\n",
    "        else:\n",
    "            break\n",
    "    return stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinHash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinHash:\n",
    "    def __init__(self, k, random_seed=random_seed):\n",
    "        \"\"\"\n",
    "        Initialize MinHash\n",
    "        k: number of hash functions\n",
    "        random_seed: random seed for reproducibility\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.seed = random_seed\n",
    "        self.totalShingles = (1 << 32) - 1\n",
    "        self.minHashSignatures = {}  # Store signatures for each set\n",
    "        self.randomNoA = self._hash_parameter()\n",
    "        self.randomNoB = self._hash_parameter()\n",
    "\n",
    "    def _hash_parameter(self):\n",
    "        \"\"\"Generate random hash parameters\"\"\"\n",
    "        randList = []\n",
    "        k_temp = self.k\n",
    "        randIndex = random.randint(0, self.totalShingles - 1)\n",
    "        randList.append(randIndex)\n",
    "        while k_temp > 0:\n",
    "            while randIndex in randList:\n",
    "                randIndex = random.randint(0, self.totalShingles - 1)\n",
    "            randList.append(randIndex)\n",
    "            k_temp -= 1\n",
    "        return randList\n",
    "\n",
    "    def process_stream(self, stream):\n",
    "        \"\"\"\n",
    "        Process streaming data\n",
    "        stream: list of [set_id, element] pairs\n",
    "        \"\"\"\n",
    "        for item in stream:\n",
    "            set_id, element = item[0], item[1]\n",
    "\n",
    "            # Initialize signature if not exists\n",
    "            if set_id not in self.minHashSignatures:\n",
    "                self.minHashSignatures[set_id] = [float(\"inf\")] * self.k\n",
    "\n",
    "            # Update minimum hash values\n",
    "            for i in range(self.k):\n",
    "                hash_value = (\n",
    "                    self.randomNoA[i] * mmh3.hash(str(element), self.seed) + self.randomNoB[i]\n",
    "                ) % self.totalShingles\n",
    "                self.minHashSignatures[set_id][i] = min(self.minHashSignatures[set_id][i], hash_value)\n",
    "\n",
    "    def estimate_similarity(self, setA=\"setA\", setB=\"setB\"):\n",
    "        \"\"\"\n",
    "        Estimate Jaccard similarity between two sets\n",
    "        setA, setB: identifiers of the sets to compare\n",
    "        \"\"\"\n",
    "        if setA not in self.minHashSignatures or setB not in self.minHashSignatures:\n",
    "            raise ValueError(\"Sets not found in signatures\")\n",
    "\n",
    "        # Count matching signatures\n",
    "        matches = sum(1 for i in range(self.k) if self.minHashSignatures[setA][i] == self.minHashSignatures[setB][i])\n",
    "\n",
    "        # Estimate Jaccard similarity\n",
    "        return matches / self.k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Jaccard: 0.9, Estimated Jaccard: 0.90625\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Parameters\n",
    "    k = 128\n",
    "    cardinality = 10000\n",
    "    jaccard_true = 0.9\n",
    "\n",
    "    # Generate synthetic stream\n",
    "    stream = generate_synthetic_stream(cardinality, jaccard_true)\n",
    "\n",
    "    # Create MinHash instance and process stream\n",
    "    minhash = MinHash(k)\n",
    "    minhash.process_stream(stream)\n",
    "\n",
    "    # Estimate Jaccard similarity\n",
    "    jaccard_est = minhash.estimate_similarity()\n",
    "    print(f\"True Jaccard: {jaccard_true}, Estimated Jaccard: {jaccard_est}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b-bit MinHash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BbitMinHash:\n",
    "    def __init__(self, k, b, random_seed=random_seed):\n",
    "        \"\"\"\n",
    "        Initialize b-bit MinHash\n",
    "        k: number of hash functions\n",
    "        b: number of bits to keep from each hash value\n",
    "        random_seed: random seed for reproducibility\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.b = b\n",
    "        self.seed = random_seed\n",
    "        self.totalShingles = (1 << 32) - 1\n",
    "        self.minHashSignatures = {}  # Store original MinHash signatures\n",
    "        self.bbitSignatures = {}  # Store b-bit signatures\n",
    "        self.randomNoA = self._hash_parameter()\n",
    "        self.randomNoB = self._hash_parameter()\n",
    "        self.mask = (1 << b) - 1  # Mask for getting lowest b bits\n",
    "\n",
    "    def _hash_parameter(self):\n",
    "        \"\"\"Generate random hash parameters\"\"\"\n",
    "        randList = []\n",
    "        k_temp = self.k\n",
    "        randIndex = random.randint(0, self.totalShingles - 1)\n",
    "        randList.append(randIndex)\n",
    "        while k_temp > 0:\n",
    "            while randIndex in randList:\n",
    "                randIndex = random.randint(0, self.totalShingles - 1)\n",
    "            randList.append(randIndex)\n",
    "            k_temp -= 1\n",
    "        return randList\n",
    "\n",
    "    def _get_lowest_b_bits(self, value):\n",
    "        \"\"\"Extract lowest b bits from a value\"\"\"\n",
    "        return value & self.mask\n",
    "\n",
    "    def process_stream(self, stream):\n",
    "        \"\"\"\n",
    "        Process streaming data\n",
    "        stream: list of [set_id, element] pairs\n",
    "        \"\"\"\n",
    "        # First compute regular MinHash signatures\n",
    "        for item in stream:\n",
    "            set_id, element = item[0], item[1]\n",
    "\n",
    "            # Initialize signature if not exists\n",
    "            if set_id not in self.minHashSignatures:\n",
    "                self.minHashSignatures[set_id] = [float(\"inf\")] * self.k\n",
    "\n",
    "            # Update minimum hash values\n",
    "            for i in range(self.k):\n",
    "                hash_value = (\n",
    "                    self.randomNoA[i] * mmh3.hash(str(element), self.seed) + self.randomNoB[i]\n",
    "                ) % self.totalShingles\n",
    "                self.minHashSignatures[set_id][i] = min(self.minHashSignatures[set_id][i], hash_value)\n",
    "\n",
    "        # Convert MinHash signatures to b-bit signatures\n",
    "        for set_id in self.minHashSignatures:\n",
    "            self.bbitSignatures[set_id] = [\n",
    "                self._get_lowest_b_bits(int(value)) for value in self.minHashSignatures[set_id]\n",
    "            ]\n",
    "\n",
    "    def estimate_similarity(self, setA=\"setA\", setB=\"setB\"):\n",
    "        \"\"\"\n",
    "        Estimate Jaccard similarity between two sets using b-bit MinHash\n",
    "        setA, setB: identifiers of the sets to compare\n",
    "        \"\"\"\n",
    "        if setA not in self.bbitSignatures or setB not in self.bbitSignatures:\n",
    "            raise ValueError(\"Sets not found in signatures\")\n",
    "\n",
    "        # Count matching b-bit signatures\n",
    "        matches = sum(1 for i in range(self.k) if self.bbitSignatures[setA][i] == self.bbitSignatures[setB][i])\n",
    "\n",
    "        # Estimate Jaccard similarity using b-bit MinHash formula\n",
    "        # Formula: (matches/k - 1/2^b)/(1 - 1/2^b)\n",
    "        denominator = 1.0 - 1.0 / (1 << self.b)\n",
    "        numerator = matches / float(self.k) - 1.0 / (1 << self.b)\n",
    "\n",
    "        return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Jaccard: 0.9, Estimated Jaccard: 0.890625\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Parameters\n",
    "    k = 128\n",
    "    b = 1  # number of bits to keep\n",
    "    cardinality = 10000\n",
    "    jaccard_true = 0.9\n",
    "\n",
    "    # Generate synthetic stream\n",
    "    stream = generate_synthetic_stream(cardinality, jaccard_true)\n",
    "\n",
    "    # Create b-bit MinHash instance and process stream\n",
    "    bbit_minhash = BbitMinHash(k, b)\n",
    "    bbit_minhash.process_stream(stream)\n",
    "\n",
    "    # Estimate Jaccard similarity\n",
    "    jaccard_est = bbit_minhash.estimate_similarity()\n",
    "    print(f\"True Jaccard: {jaccard_true}, Estimated Jaccard: {jaccard_est}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Odd Sketch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OddSketch:\n",
    "    def __init__(self, k, z, random_seed=random_seed):\n",
    "        \"\"\"\n",
    "        Initialize Odd Sketch\n",
    "        k: number of hash functions (for MinHash)\n",
    "        z: number of bits in Odd Sketch\n",
    "        random_seed: random seed for reproducibility\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.z = z\n",
    "        self.seed = random_seed\n",
    "        self.totalShingles = (1 << 32) - 1\n",
    "        self.minHashSignatures = {}  # Store MinHash signatures\n",
    "        self.oddSketches = {}  # Store Odd Sketches\n",
    "        self.randomNoA = self._hash_parameter()\n",
    "        self.randomNoB = self._hash_parameter()\n",
    "\n",
    "    def _hash_parameter(self):\n",
    "        \"\"\"Generate random hash parameters\"\"\"\n",
    "        randList = []\n",
    "        k_temp = self.k\n",
    "        randIndex = random.randint(0, self.totalShingles - 1)\n",
    "        randList.append(randIndex)\n",
    "        while k_temp > 0:\n",
    "            while randIndex in randList:\n",
    "                randIndex = random.randint(0, self.totalShingles - 1)\n",
    "            randList.append(randIndex)\n",
    "            k_temp -= 1\n",
    "        return randList\n",
    "\n",
    "    def _compute_odd_sketch(self, minhash_signature):\n",
    "        \"\"\"\n",
    "        Compute Odd Sketch from MinHash signature\n",
    "        Uses XOR-based sketching\n",
    "        \"\"\"\n",
    "        odd_sketch = np.zeros(self.z, dtype=bool)\n",
    "\n",
    "        for i in range(self.k):\n",
    "            # Hash (i, minhash_value) to position in odd sketch\n",
    "            position = mmh3.hash(str((i, minhash_signature[i])), self.seed) % self.z\n",
    "            odd_sketch[position] ^= True  # XOR operation\n",
    "\n",
    "        return odd_sketch\n",
    "\n",
    "    def process_stream(self, stream):\n",
    "        \"\"\"\n",
    "        Process streaming data\n",
    "        stream: list of [set_id, element] pairs\n",
    "        \"\"\"\n",
    "        # First compute regular MinHash signatures\n",
    "        for item in stream:\n",
    "            set_id, element = item[0], item[1]\n",
    "\n",
    "            # Initialize signature if not exists\n",
    "            if set_id not in self.minHashSignatures:\n",
    "                self.minHashSignatures[set_id] = [float(\"inf\")] * self.k\n",
    "\n",
    "            # Update minimum hash values\n",
    "            for i in range(self.k):\n",
    "                hash_value = (\n",
    "                    self.randomNoA[i] * mmh3.hash(str(element), self.seed) + self.randomNoB[i]\n",
    "                ) % self.totalShingles\n",
    "                self.minHashSignatures[set_id][i] = min(self.minHashSignatures[set_id][i], hash_value)\n",
    "\n",
    "        # Convert MinHash signatures to Odd Sketches\n",
    "        for set_id in self.minHashSignatures:\n",
    "            self.oddSketches[set_id] = self._compute_odd_sketch(self.minHashSignatures[set_id])\n",
    "\n",
    "    def estimate_similarity(self, setA=\"setA\", setB=\"setB\"):\n",
    "        \"\"\"\n",
    "        Estimate Jaccard similarity between two sets using Odd Sketch\n",
    "        setA, setB: identifiers of the sets to compare\n",
    "        \"\"\"\n",
    "        if setA not in self.oddSketches or setB not in self.oddSketches:\n",
    "            raise ValueError(\"Sets not found in sketches\")\n",
    "\n",
    "        # Count differing bits between odd sketches\n",
    "        hamming_distance = np.sum(self.oddSketches[setA] != self.oddSketches[setB])\n",
    "\n",
    "        # Estimate Jaccard similarity using Odd Sketch formula\n",
    "        # J = 1 + (z/4k)ln(1 - 2d/z)\n",
    "        # where d is the Hamming distance and z is the sketch size\n",
    "        if hamming_distance == self.z:\n",
    "            return 0.0\n",
    "\n",
    "        similarity = 1.0 + (self.z / (4.0 * self.k)) * np.log(1.0 - (2.0 * hamming_distance) / self.z)\n",
    "\n",
    "        # Clamp similarity to [0,1]\n",
    "        return max(0.0, min(1.0, similarity))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Jaccard: 0.9, Estimated Jaccard: 0.9270932291919122\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Parameters\n",
    "    k = 128\n",
    "    z = 512  # Odd Sketch size\n",
    "    cardinality = 10000\n",
    "    jaccard_true = 0.9\n",
    "\n",
    "    # Generate synthetic stream\n",
    "    stream = generate_synthetic_stream(cardinality, jaccard_true)\n",
    "\n",
    "    # Create Odd Sketch instance and process stream\n",
    "    odd_sketch = OddSketch(k, z)\n",
    "    odd_sketch.process_stream(stream)\n",
    "\n",
    "    # Estimate Jaccard similarity\n",
    "    jaccard_est = odd_sketch.estimate_similarity()\n",
    "    print(f\"True Jaccard: {jaccard_true}, Estimated Jaccard: {jaccard_est}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaxLogHash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxLogHash:\n",
    "    def __init__(self, k, random_seed=random_seed):\n",
    "        self.k = k\n",
    "        self.seed = random_seed\n",
    "        self.totalShingles = (1 << 32) - 1\n",
    "        self.maxShingleID = {}\n",
    "        self.randomNoA = self._hash_parameter()\n",
    "        self.randomNoB = self._hash_parameter()\n",
    "\n",
    "    def _hash_parameter(self):\n",
    "        randList = []\n",
    "        k_temp = self.k\n",
    "        randIndex = random.randint(0, self.totalShingles - 1)\n",
    "        randList.append(randIndex)\n",
    "        while k_temp > 0:\n",
    "            while randIndex in randList:\n",
    "                randIndex = random.randint(0, self.totalShingles - 1)\n",
    "            randList.append(randIndex)\n",
    "            k_temp -= 1\n",
    "        return randList\n",
    "\n",
    "    def process_stream(self, stream):\n",
    "        for item in stream:\n",
    "            if item[0] in self.maxShingleID:\n",
    "                max_hash_val_list = self.maxShingleID[item[0]][0]\n",
    "                max_hash_sig_list = self.maxShingleID[item[0]][1]\n",
    "\n",
    "                for x in range(self.k):\n",
    "                    temp = (\n",
    "                        self.randomNoA[x] * mmh3.hash(str(item[1]), self.seed) + self.randomNoB[x]\n",
    "                    ) % self.totalShingles\n",
    "                    temp = temp / float(self.totalShingles)\n",
    "                    log_temp = -math.log(temp, 2)\n",
    "                    hash_val = math.ceil(log_temp)\n",
    "\n",
    "                    if hash_val > max_hash_val_list[x]:\n",
    "                        max_hash_val_list[x] = hash_val\n",
    "                        max_hash_sig_list[x] = 1\n",
    "                    elif hash_val == max_hash_val_list[x]:\n",
    "                        max_hash_sig_list[x] = 0\n",
    "\n",
    "                self.maxShingleID[item[0]][0] = max_hash_val_list\n",
    "                self.maxShingleID[item[0]][1] = max_hash_sig_list\n",
    "            else:\n",
    "                max_hash_val_list = [-1] * self.k\n",
    "                max_hash_sig_list = [0] * self.k\n",
    "                self.maxShingleID[item[0]] = [max_hash_val_list, max_hash_sig_list]\n",
    "\n",
    "    def estimate_similarity(self, setA=\"setA\", setB=\"setB\"):\n",
    "        con = 0\n",
    "        for x in range(self.k):\n",
    "            if self.maxShingleID[setA][0][x] > self.maxShingleID[setB][0][x] and self.maxShingleID[setA][1][x] == 1:\n",
    "                con += 1\n",
    "            elif self.maxShingleID[setA][0][x] < self.maxShingleID[setB][0][x] and self.maxShingleID[setB][1][x] == 1:\n",
    "                con += 1\n",
    "\n",
    "        jaccard_sim = 1.0 - con * (1 / float(self.k)) * (1 / 0.7213)\n",
    "        return jaccard_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Jaccard: 0.9, Estimated Jaccard: 0.9458443088867323\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Parameters\n",
    "    k = 128\n",
    "    cardinality = 10000\n",
    "    jaccard_true = 0.9\n",
    "\n",
    "    # Generate synthetic stream\n",
    "    stream = generate_synthetic_stream(cardinality, jaccard_true)\n",
    "\n",
    "    # Create MaxLogHash instance and process stream\n",
    "    maxlog = MaxLogHash(k)\n",
    "    maxlog.process_stream(stream)\n",
    "\n",
    "    # Estimate Jaccard similarity\n",
    "    jaccard_est = maxlog.estimate_similarity()\n",
    "    print(f\"True Jaccard: {jaccard_true}, Estimated Jaccard: {jaccard_est}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_all_methods():\n",
    "    \"\"\"\n",
    "    Compare all similarity estimation methods\n",
    "    \"\"\"\n",
    "    # Parameters\n",
    "    k = 128  # Number of hash functions\n",
    "    cardinality = 10000\n",
    "    jaccard_true = 0.9\n",
    "\n",
    "    # Generate synthetic stream\n",
    "    stream = generate_synthetic_stream(cardinality, jaccard_true)\n",
    "\n",
    "    # Regular MinHash estimation\n",
    "    minhash = MinHash(k)\n",
    "    minhash.process_stream(stream)\n",
    "    jaccard_est_min = minhash.estimate_similarity()\n",
    "\n",
    "    # b-bit MinHash estimation\n",
    "    b = 1  # b-bit MinHash parameter\n",
    "    bbit_minhash = BbitMinHash(k, b)\n",
    "    bbit_minhash.process_stream(stream)\n",
    "    jaccard_est_bbit = bbit_minhash.estimate_similarity()\n",
    "\n",
    "    # Odd Sketch estimation\n",
    "    z = 512  # Odd Sketch size\n",
    "    odd_sketch = OddSketch(k, z)\n",
    "    odd_sketch.process_stream(stream)\n",
    "    jaccard_est_odd = odd_sketch.estimate_similarity()\n",
    "\n",
    "    # MaxLogHash estimation\n",
    "    maxlog = MaxLogHash(k)\n",
    "    maxlog.process_stream(stream)\n",
    "    jaccard_est_max = maxlog.estimate_similarity()\n",
    "\n",
    "    print(f\"True Jaccard: {jaccard_true}\")\n",
    "    print(f\"MinHash Estimation: {jaccard_est_min:.4f}\")\n",
    "    print(f\"b-bit MinHash Estimation: {jaccard_est_bbit:.4f}\")\n",
    "    print(f\"Odd Sketch Estimation: {jaccard_est_odd:.4f}\")\n",
    "    print(f\"MaxLogHash Estimation: {jaccard_est_max:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Jaccard: 0.9\n",
      "MinHash Estimation: 0.8828\n",
      "b-bit MinHash Estimation: 0.9219\n",
      "Odd Sketch Estimation: 0.9016\n",
      "MaxLogHash Estimation: 0.8917\n"
     ]
    }
   ],
   "source": [
    "compare_all_methods()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic datasets\n",
    "\n",
    "Generate set A by randomly selecting n different numbers from I\n",
    "\n",
    "Generate set B by randomly selecting $|A \\cup B| = \\frac{J_{A, B}|A|}{1+J_{A, B}}$ different numbers from set A and $n - |A \\cup B|$ different numbers from set I\\A\n",
    "\n",
    "n = 10,000 by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanced set-pairs (i.e., |A| = |B| = n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unbalanced set-pairs (i.e., |A| != |B|)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-world datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filepath):\n",
    "    with open(filepath, \"r\") as file:\n",
    "        dataset = pl.DataFrame(np.loadtxt(file, dtype=int))\n",
    "\n",
    "    item_record_pairs = {}\n",
    "\n",
    "    for record_id, record in enumerate(dataset):\n",
    "        for item in record:\n",
    "            if item not in item_record_pairs:\n",
    "                item_record_pairs[item] = []\n",
    "            item_record_pairs[item].append(record_id)\n",
    "\n",
    "    pairs = [(item, rec) for item, recs in item_record_pairs.items() for rec in recs]\n",
    "\n",
    "    return dataset, item_record_pairs, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MUSHROOM dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mushroom_dataset_path = \"./data/mushroom.dat\"\n",
    "mushroom = load_dataset(mushroom_dataset_path)\n",
    "\n",
    "mushroom_dataset = mushroom[0]\n",
    "mushroom_item_record_pairs = mushroom[1]\n",
    "mushroom_pairs = mushroom[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 8,124 records with 119 distinct items\n",
    "- 186,852 item-record pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 23)\n",
      "┌──────────┬──────────┬──────────┬──────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
      "│ column_0 ┆ column_1 ┆ column_2 ┆ column_3 ┆ … ┆ column_19 ┆ column_20 ┆ column_21 ┆ column_22 │\n",
      "│ ---      ┆ ---      ┆ ---      ┆ ---      ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
      "│ i32      ┆ i32      ┆ i32      ┆ i32      ┆   ┆ i32       ┆ i32       ┆ i32       ┆ i32       │\n",
      "╞══════════╪══════════╪══════════╪══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ 1        ┆ 3        ┆ 9        ┆ 13       ┆ … ┆ 93        ┆ 98        ┆ 107       ┆ 113       │\n",
      "│ 2        ┆ 3        ┆ 9        ┆ 14       ┆ … ┆ 93        ┆ 99        ┆ 108       ┆ 114       │\n",
      "│ 2        ┆ 4        ┆ 9        ┆ 15       ┆ … ┆ 93        ┆ 99        ┆ 108       ┆ 115       │\n",
      "│ 1        ┆ 3        ┆ 10       ┆ 15       ┆ … ┆ 93        ┆ 98        ┆ 107       ┆ 113       │\n",
      "│ 2        ┆ 3        ┆ 9        ┆ 16       ┆ … ┆ 94        ┆ 99        ┆ 109       ┆ 114       │\n",
      "└──────────┴──────────┴──────────┴──────────┴───┴───────────┴───────────┴───────────┴───────────┘\n",
      "(8124, 23)\n",
      "119\n",
      "186852\n"
     ]
    }
   ],
   "source": [
    "print(mushroom_dataset[:5])\n",
    "print(mushroom_dataset.shape)\n",
    "print(len(mushroom_item_record_pairs))\n",
    "print(len(mushroom_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONNECT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "connect_dataset_path = \"./data/connect.dat\"\n",
    "connect = load_dataset(connect_dataset_path)\n",
    "\n",
    "connect_dataset = connect[0]\n",
    "connect_item_record_pairs = connect[1]\n",
    "connect_pairs = connect[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 67,557 records with 127 distinct items\n",
    "- 2,904,951 item-record pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 43)\n",
      "┌──────────┬──────────┬──────────┬──────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
      "│ column_0 ┆ column_1 ┆ column_2 ┆ column_3 ┆ … ┆ column_39 ┆ column_40 ┆ column_41 ┆ column_42 │\n",
      "│ ---      ┆ ---      ┆ ---      ┆ ---      ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
      "│ i32      ┆ i32      ┆ i32      ┆ i32      ┆   ┆ i32       ┆ i32       ┆ i32       ┆ i32       │\n",
      "╞══════════╪══════════╪══════════╪══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ 1        ┆ 4        ┆ 7        ┆ 10       ┆ … ┆ 118       ┆ 121       ┆ 124       ┆ 127       │\n",
      "│ 1        ┆ 4        ┆ 7        ┆ 10       ┆ … ┆ 118       ┆ 121       ┆ 124       ┆ 127       │\n",
      "│ 1        ┆ 4        ┆ 7        ┆ 10       ┆ … ┆ 118       ┆ 121       ┆ 124       ┆ 127       │\n",
      "│ 1        ┆ 4        ┆ 7        ┆ 10       ┆ … ┆ 118       ┆ 121       ┆ 124       ┆ 127       │\n",
      "│ 1        ┆ 5        ┆ 7        ┆ 10       ┆ … ┆ 118       ┆ 121       ┆ 124       ┆ 127       │\n",
      "└──────────┴──────────┴──────────┴──────────┴───┴───────────┴───────────┴───────────┴───────────┘\n",
      "(67557, 43)\n",
      "129\n",
      "2904951\n"
     ]
    }
   ],
   "source": [
    "print(connect_dataset[:5])\n",
    "print(connect_dataset.shape)\n",
    "print(len(connect_item_record_pairs))\n",
    "print(len(connect_pairs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
