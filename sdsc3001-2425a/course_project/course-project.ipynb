{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDSC3001 - Course Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard similarity coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(set1, set2):\n",
    "    intersection = set1.intersection(set2)\n",
    "    union = set1.union(set2)\n",
    "    return len(intersection) / len(union)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "set1 = {\"a\", \"b\", \"c\", \"d\"}\n",
    "set2 = {\"c\", \"d\", \"e\", \"f\"}\n",
    "\n",
    "similarity = jaccard_similarity(set1, set2)\n",
    "print(f\"Jaccard Similarity: {similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sketching techniques for the Jaccard similarity coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "random_seed = 42\n",
    "random.seed(random_seed)\n",
    "# Parameters\n",
    "k = 128  # Number of hash functions\n",
    "n = 10_000  # cardinality of the sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_balanced_synthetic_stream(n, jaccard_true):\n",
    "    total_num = n * 2\n",
    "    similarity_coefficient = (2 * jaccard_true) / (1 + jaccard_true)\n",
    "    the_same_index = total_num / 2 * similarity_coefficient\n",
    "    setA_uni_index = total_num / 2 * 1\n",
    "    setB_uni_index = total_num / 2 * (2 - similarity_coefficient)\n",
    "\n",
    "    stream = []\n",
    "    for num in range(total_num):\n",
    "        if num <= the_same_index:\n",
    "            stream.append([\"setA\", num])\n",
    "            stream.append([\"setB\", num])\n",
    "        elif num <= setA_uni_index:\n",
    "            stream.append([\"setA\", num])\n",
    "        elif num <= setB_uni_index:\n",
    "            stream.append([\"setB\", num])\n",
    "        else:\n",
    "            break\n",
    "    return stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unbalanced_synthetic_stream(n, jaccard_true): ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "print(os.getcwd() in sys.path)\n",
    "sys.path.append(os.getcwd())\n",
    "print(os.getcwd() in sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hashSketch import MinHash, B_bitMinHash, OddSketch, MaxLogHash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinHash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b-bit MinHash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Odd Sketch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaxLogHash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "### Synthetic datasets\n",
    "\n",
    "Generate set A by randomly selecting n different numbers from I\n",
    "\n",
    "Generate set B by randomly selecting $|A \\cup B| = \\frac{J_{A, B}|A|}{1+J_{A, B}}$ different numbers from set A and $n - |A \\cup B|$ different numbers from set I\\A\n",
    "\n",
    "n = 10,000 by default\n",
    "\n",
    "- Balanced set-pairs (i.e., |A| = |B| = n)\n",
    "- Unbalanced set-pairs (i.e., |A| != |B|)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_all_methods(jaccard_true, k=128, n=10000):\n",
    "    \"\"\"\n",
    "    Compare all similarity estimation methods\n",
    "    jaccard_true: true Jaccard similarity\n",
    "    k: number of hash functions\n",
    "    n: number of elements in the stream (cardinality)\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate synthetic stream\n",
    "    stream = generate_balanced_synthetic_stream(n, jaccard_true)\n",
    "    # print(stream[:10])\n",
    "\n",
    "    # Regular MinHash estimation\n",
    "    minhash = MinHash(k)\n",
    "    minhash.process_stream(stream)\n",
    "    jaccard_est_min = minhash.estimate_similarity()\n",
    "\n",
    "    # b-bit MinHash estimation\n",
    "    b = 1  # b-bit MinHash parameter\n",
    "    bbit_minhash = B_bitMinHash(k, b)\n",
    "    bbit_minhash.process_stream(stream)\n",
    "    jaccard_est_bbit = bbit_minhash.estimate_similarity()\n",
    "\n",
    "    # Odd Sketch estimation\n",
    "    z = 512  # Odd Sketch size\n",
    "    odd_sketch = OddSketch(k, z)\n",
    "    odd_sketch.process_stream(stream)\n",
    "    jaccard_est_odd = odd_sketch.estimate_similarity()\n",
    "\n",
    "    # MaxLogHash estimation\n",
    "    maxlog = MaxLogHash(k)\n",
    "    maxlog.process_stream(stream)\n",
    "    jaccard_est_max = maxlog.estimate_similarity()\n",
    "\n",
    "    # print(f\"{jaccard_true}, {jaccard_est_min}, {jaccard_est_bbit}, {jaccard_est_odd}, {jaccard_est_max}\")\n",
    "    return jaccard_est_min, jaccard_est_bbit, jaccard_est_odd, jaccard_est_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_all_methods(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store results\n",
    "results = []\n",
    "\n",
    "for i in range(80, 101):\n",
    "    jaccard_true = i / 100\n",
    "    jaccard_est_min, jaccard_est_bbit, jaccard_est_odd, jaccard_est_max = compare_all_methods(jaccard_true)\n",
    "\n",
    "    # Append the results to the list\n",
    "    results.append([jaccard_true, jaccard_est_min, jaccard_est_bbit, jaccard_est_odd, jaccard_est_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "columns = [\"True Jaccard\", \"MinHash\", \"b-bit MinHash\", \"Odd Sketch\", \"MaxLogHash\"]\n",
    "df = pl.DataFrame(results, schema=columns, orient=\"row\")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the size of the plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot the data\n",
    "for method in columns[1:]:\n",
    "    plt.plot(df[\"True Jaccard\"], df[method], label=method)\n",
    "\n",
    "# Set the title and labels\n",
    "plt.title(\"Jaccard Similarity Estimates by Different Methods\")\n",
    "plt.xlabel(\"True Jaccard Index\")\n",
    "plt.ylabel(\"Estimated Jaccard Index\")\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate absolute errors\n",
    "df = df.with_columns(\n",
    "    [\n",
    "        pl.col(\"MinHash\").sub(pl.col(\"True Jaccard\")).abs().alias(\"MinHash_error\"),\n",
    "        pl.col(\"b-bit MinHash\").sub(pl.col(\"True Jaccard\")).abs().alias(\"bbit_error\"),\n",
    "        pl.col(\"Odd Sketch\").sub(pl.col(\"True Jaccard\")).abs().alias(\"oddsketch_error\"),\n",
    "        pl.col(\"MaxLogHash\").sub(pl.col(\"True Jaccard\")).abs().alias(\"maxlog_error\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot each method's error\n",
    "plt.plot(df[\"True Jaccard\"], df[\"MinHash_error\"], \"o-\", label=\"MinHash\", color=\"blue\")\n",
    "plt.plot(df[\"True Jaccard\"], df[\"bbit_error\"], \"s-\", label=\"b-bit MinHash\", color=\"red\")\n",
    "plt.plot(df[\"True Jaccard\"], df[\"oddsketch_error\"], \"^-\", label=\"Odd Sketch\", color=\"green\")\n",
    "plt.plot(df[\"True Jaccard\"], df[\"maxlog_error\"], \"D-\", label=\"MaxLogHash\", color=\"purple\")\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel(\"True Jaccard Similarity\")\n",
    "plt.ylabel(\"Absolute Error\")\n",
    "plt.title(\"Absolute Error vs True Jaccard Similarity\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "plt.legend()\n",
    "\n",
    "# Set x-axis limits\n",
    "plt.xlim(0.78, 1.02)\n",
    "\n",
    "# Format y-axis to show small values clearly\n",
    "plt.yscale(\"log\")  # Use log scale for better visualization of small errors\n",
    "plt.ylim(0.001, 0.1)\n",
    "\n",
    "# Add horizontal lines for reference\n",
    "plt.axhline(y=0.01, color=\"gray\", linestyle=\"--\", alpha=0.3)\n",
    "plt.axhline(y=0.05, color=\"gray\", linestyle=\"--\", alpha=0.3)\n",
    "\n",
    "# Adjust layout to prevent label cutoff\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-world datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filepath):\n",
    "    with open(filepath, \"r\") as file:\n",
    "        dataset = pl.DataFrame(np.loadtxt(file, dtype=int))\n",
    "\n",
    "    item_record_pairs = {}\n",
    "\n",
    "    for record_id, record in enumerate(dataset):\n",
    "        for item in record:\n",
    "            if item not in item_record_pairs:\n",
    "                item_record_pairs[item] = []\n",
    "            item_record_pairs[item].append(record_id)\n",
    "\n",
    "    pairs = [(item, rec) for item, recs in item_record_pairs.items() for rec in recs]\n",
    "\n",
    "    return dataset, item_record_pairs, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MUSHROOM dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mushroom_dataset_path = \"./data/mushroom.dat\"\n",
    "mushroom = load_dataset(mushroom_dataset_path)\n",
    "\n",
    "mushroom_dataset = mushroom[0]\n",
    "mushroom_item_record_pairs = mushroom[1]\n",
    "mushroom_pairs = mushroom[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 8,124 records with 119 distinct items\n",
    "- 186,852 item-record pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mushroom_dataset[:5])\n",
    "print(mushroom_dataset.shape)\n",
    "print(len(mushroom_item_record_pairs))\n",
    "print(len(mushroom_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_stream_from_dataset(dataset):\n",
    "#     \"\"\"\n",
    "#     Convert dataset into a stream of [item_id, record_id] pairs\n",
    "#     dataset: DataFrame where each row is a record containing items\n",
    "\n",
    "#     Returns:\n",
    "#     stream: list of [item_id, record_id] pairs\n",
    "#     \"\"\"\n",
    "#     stream = []\n",
    "\n",
    "#     # Iterate through each record\n",
    "#     for record_id, record in enumerate(dataset.iter_rows()):\n",
    "#         # For each item in the record\n",
    "#         for item in record:\n",
    "#             if item != 0:  # Assuming 0 is not a valid item ID\n",
    "#                 # Add (item, record) pair to stream\n",
    "#                 stream.append([f\"set{record_id}\", item])\n",
    "#                 # print(record_id, item)\n",
    "\n",
    "#     return stream\n",
    "\n",
    "\n",
    "# def analyze_stream(stream):\n",
    "#     \"\"\"\n",
    "#     Print statistics about the stream\n",
    "#     \"\"\"\n",
    "#     unique_items = len(set(pair[0] for pair in stream))\n",
    "#     unique_records = len(set(pair[1] for pair in stream))\n",
    "#     total_pairs = len(stream)\n",
    "\n",
    "#     print(f\"Number of unique items: {unique_items}\")\n",
    "#     print(f\"Number of records: {unique_records}\")\n",
    "#     print(f\"Total item-record pairs: {total_pairs}\")\n",
    "\n",
    "# # To estimate similarity between two items\n",
    "# def get_item_similarity(minhash, item1, item2):\n",
    "#     return minhash.estimate_similarity(f\"item_{item1}\", f\"item_{item2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert mushroom_dataset to a stream of [set_id, element] pairs\n",
    "# stream = []\n",
    "\n",
    "# for record_id, record in enumerate(mushroom_dataset):\n",
    "#     for item in record:\n",
    "#         stream.append([f\"set{record_id}\", item])\n",
    "\n",
    "# # Now you can pass the stream to the sketch methods\n",
    "# # Example usage with MinHash\n",
    "# minhash = MinHash(k=128)\n",
    "# minhash.process_stream(stream)\n",
    "# jaccard_est_min = minhash.estimate_similarity(setA=\"set0\", setB=\"set1\")\n",
    "\n",
    "# # Example usage with MaxLogHash\n",
    "# maxlog = MaxLogHash(k=128)\n",
    "# maxlog.process_stream(stream)\n",
    "# jaccard_est_max = maxlog.estimate_similarity(setA=\"set0\", setB=\"set1\")\n",
    "\n",
    "# print(f\"MinHash Jaccard Estimate: {jaccard_est_min}\")\n",
    "# print(f\"MaxLogHash Jaccard Estimate: {jaccard_est_max}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONNECT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connect_dataset_path = \"./data/connect.dat\"\n",
    "connect = load_dataset(connect_dataset_path)\n",
    "\n",
    "connect_dataset = connect[0]\n",
    "connect_item_record_pairs = connect[1]\n",
    "connect_pairs = connect[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 67,557 records with 127 distinct items\n",
    "- 2,904,951 item-record pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(connect_dataset[:5])\n",
    "print(connect_dataset.shape)\n",
    "print(len(connect_item_record_pairs))\n",
    "print(len(connect_pairs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
